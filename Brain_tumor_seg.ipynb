{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ltbYAl6qtWxv-CZzehGpI3jAFbliWKok",
      "authorship_tag": "ABX9TyPCxbQtZc2qj2oqUdf/XVJ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedsajidhussain/ML-Assessment/blob/main/Brain_tumor_seg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3TFGlwdeg5e",
        "outputId": "0883b4e3-54d4-4eb6-949d-4a2eb6d32402"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from keras import backend, optimizers"
      ],
      "metadata": {
        "id": "mL9NrtpZ--n8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "5l29sY2St1rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_directory = '/content/drive/MyDrive/Dataset/images/'\n",
        "mask_directory = '/content/drive/MyDrive/Dataset/masks/'\n"
      ],
      "metadata": {
        "id": "AyU7-efv_ABy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "\n",
        "dir= \"/content/drive/MyDrive/Dataset/masks/\"\n",
        "\n",
        "# List all files in the folder\n",
        "files = os.listdir(dir)\n",
        "\n",
        "# Sort the files\n",
        "sorted_files = sorted(files)\n",
        "\n",
        "# Rename the files in sorted order\n",
        "for index, old_name in enumerate(sorted_files):\n",
        "    file_extension = os.path.splitext(old_name)[1]\n",
        "    new_name = f\"img_{index + 1}{file_extension}\"\n",
        "    old_path = os.path.join(dir, old_name)\n",
        "    new_path = os.path.join(dir, new_name)\n",
        "    os.rename(old_path, new_path)\n",
        "'''"
      ],
      "metadata": {
        "id": "ZUGXOMmRrJlj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 128\n",
        "image_dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.\n",
        "mask_dataset = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.\n",
        "\n"
      ],
      "metadata": {
        "id": "K6S14B6l_DZw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = os.listdir(image_directory)\n",
        "for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
        "    if (image_name.split('.')[1] == 'tif'):\n",
        "        #print(image_directory+image_name)\n",
        "        image = cv2.imread(image_directory+image_name, 1)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        image_dataset.append(np.array(image))"
      ],
      "metadata": {
        "id": "PdOErwK5kakD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Iterate through all images in Uninfected folder, resize to 64 x 64\n",
        "#Then save into the same numpy array 'dataset' but with label 1\n",
        "\n",
        "masks = os.listdir(mask_directory)\n",
        "for i, image_name in enumerate(masks):\n",
        "    if (image_name.split('.')[1] == 'tif'):\n",
        "        image = cv2.imread(mask_directory+image_name, 0)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        mask_dataset.append(np.array(image))\n"
      ],
      "metadata": {
        "id": "oaYSXJ-j_DWz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize images\n",
        "image_dataset = np.array(image_dataset)/255.\n",
        "#D not normalize masks, just rescale to 0 to 1.\n",
        "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255."
      ],
      "metadata": {
        "id": "PLZ4EO-y_DT9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.10, random_state = 0)"
      ],
      "metadata": {
        "id": "dxfzhYd9_DRJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sanity check, view few mages\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(X_train))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(X_train[image_number], (128, 128, 3)), cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(y_train[image_number], (128, 128)), cmap='gray')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "jnW4MaBd_DPb",
        "outputId": "6fcc5451-1c4a-40e6-d0aa-5cec0e4bd10e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "#Parameters for model\n",
        "\n",
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]\n",
        "num_labels = 1  #Binary\n",
        "input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
        "batch_size = 8\n",
        "\n"
      ],
      "metadata": {
        "id": "oY36yVlD_DKp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install focal-loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enVm4aC7wZ3h",
        "outputId": "39d1c424-fd0d-4b90-96e1-f0f2cae3f4be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting focal-loss',\n",
              " '  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)',\n",
              " 'Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.10/dist-packages (from focal-loss) (2.12.0)',\n",
              " 'Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (1.4.0)',\n",
              " 'Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)',\n",
              " 'Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (23.5.26)',\n",
              " 'Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (0.4.0)',\n",
              " 'Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)',\n",
              " 'Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (1.57.0)',\n",
              " 'Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (3.9.0)',\n",
              " 'Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (0.4.14)',\n",
              " 'Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (2.12.0)',\n",
              " 'Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (16.0.6)',\n",
              " 'Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (1.23.5)',\n",
              " 'Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)',\n",
              " 'Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (23.1)',\n",
              " 'Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (3.20.3)',\n",
              " 'Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (67.7.2)',\n",
              " 'Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (1.16.0)',\n",
              " 'Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (2.12.3)',\n",
              " 'Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (2.12.0)',\n",
              " 'Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (2.3.0)',\n",
              " 'Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (4.7.1)',\n",
              " 'Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (1.14.1)',\n",
              " 'Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->focal-loss) (0.33.0)',\n",
              " 'Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal-loss) (0.41.2)',\n",
              " 'Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.2->focal-loss) (0.2.0)',\n",
              " 'Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.2->focal-loss) (1.10.1)',\n",
              " 'Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (2.17.3)',\n",
              " 'Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (1.0.0)',\n",
              " 'Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (3.4.4)',\n",
              " 'Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (2.31.0)',\n",
              " 'Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (0.7.1)',\n",
              " 'Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (2.3.7)',\n",
              " 'Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (5.3.1)',\n",
              " 'Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (0.3.0)',\n",
              " 'Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (4.9)',\n",
              " 'Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (1.3.1)',\n",
              " 'Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (3.2.0)',\n",
              " 'Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (3.4)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (2.0.4)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (2023.7.22)',\n",
              " 'Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (2.1.3)',\n",
              " 'Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (0.5.0)',\n",
              " 'Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.2->focal-loss) (3.2.2)',\n",
              " 'Installing collected packages: focal-loss',\n",
              " 'Successfully installed focal-loss-0.0.7']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FOCAL LOSS AND DICE METRIC\n",
        "#Focal loss helps focus more on tough to segment classes.\n",
        "from focal_loss import BinaryFocalLoss"
      ],
      "metadata": {
        "id": "Tum86PawkhUm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMIKW_g-zuB_",
        "outputId": "9025713c-860b-4455-a360-a5c1bb283e16"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'   Dataset   ISBI2023-One-Shot-WM-Tract-Segmentation   mrtrix3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Dataset/models.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYeLTv04zxUH",
        "outputId": "dc1b8146-e576-49cf-b15e-0a166907e8eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-29 14:23:27.152165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-29 14:23:33.422656: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Model: \"UNet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  640         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 32, 32, 1024  0           ['activation_9[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1536  0           ['up_sampling2d[0][0]',          \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 512)  7078400     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0          ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 768)  0           ['up_sampling2d_1[0][0]',        \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1769728     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 25  0          ['activation_13[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 38  0           ['up_sampling2d_2[0][0]',        \n",
            "                                4)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 128, 12  442496      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_14[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_15[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 12  0          ['activation_15[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_3[0][0]',        \n",
            "                                2)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 256, 256, 64  110656      ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 256, 256, 64  256        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 256, 256, 64  256        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 256, 256, 1)  4          ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 256, 256, 1)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,401,349\n",
            "Trainable params: 31,389,571\n",
            "Non-trainable params: 11,778\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models , layers, regularizers\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "dLR0Wb24xbWs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB4heis41XvQ",
        "outputId": "9af643b1-79b5-4323-814e-e00ac9d1c124"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'   Dataset   ISBI2023-One-Shot-WM-Tract-Segmentation   mrtrix3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Try various models: Unet, Attention_UNet, and Attention_ResUnet\n",
        "#Rename original python file from 224_225_226_models.py to models.py\n",
        "from Dataset.models import Attention_ResUNet, UNet, Attention_UNet, dice_coef, dice_coef_loss, jacard_coef"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-HdQLRoyQBr",
        "outputId": "5f00cb90-167f-4fc6-cb27-f1bc9bead0d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  640         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 32, 32, 1024  0           ['activation_9[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1536  0           ['up_sampling2d[0][0]',          \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 512)  7078400     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0          ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 768)  0           ['up_sampling2d_1[0][0]',        \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1769728     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 25  0          ['activation_13[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 38  0           ['up_sampling2d_2[0][0]',        \n",
            "                                4)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 128, 12  442496      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_14[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_15[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 12  0          ['activation_15[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_3[0][0]',        \n",
            "                                2)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 256, 256, 64  110656      ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 256, 256, 64  256        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 256, 256, 64  256        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 256, 256, 1)  4          ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 256, 256, 1)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,401,349\n",
            "Trainable params: 31,389,571\n",
            "Non-trainable params: 11,778\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZsHEBblBEb3",
        "outputId": "9d703dbf-cff7-4d33-b997-a96e098fff3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " brain_Attention_UNet_50epochs_B_focal.hdf5\n",
            " brain_AttResUnet_50epochs_B_focal.hdf5\n",
            " brain_UNet_50epochs_B_focal.hdf5\n",
            "'Colab Notebooks'\n",
            " Dataset\n",
            " ISBI2023-One-Shot-WM-Tract-Segmentation\n",
            " mrtrix3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Try various models: Unet, Attention_UNet, and Attention_ResUnet\n",
        "#Rename original python file from 224_225_226_models.py to models.py\n",
        "from Dataset.models import Attention_ResUNet, UNet, Attention_UNet, dice_coef, dice_coef_loss, jacard_coef\n",
        "\n",
        "'''\n",
        "UNet\n",
        "'''\n",
        "unet_model = UNet(input_shape)\n",
        "unet_model.compile(optimizer=Adam(lr = 1e-2), loss=BinaryFocalLoss(gamma=2),\n",
        "              metrics=['accuracy', jacard_coef])\n",
        "\n",
        "\n",
        "print(unet_model.summary())\n",
        "\n",
        "start1 = datetime.now()\n",
        "unet_history = unet_model.fit(X_train, y_train,\n",
        "                    verbose=1,\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=50)\n",
        "\n",
        "stop1 = datetime.now()\n",
        "#Execution time of the model\n",
        "execution_time_Unet = stop1-start1\n",
        "print(\"UNet execution time is: \", execution_time_Unet)\n",
        "\n",
        "unet_model.save('brain_UNet_50epochs_B_focal.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "EMdr4h6b_DHj",
        "outputId": "218d16e7-0608-43ab-c2ea-2304b642c0fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d424a2282af8>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m '''\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0munet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m unet_model.compile(optimizer=Adam(lr = 1e-2), loss=BinaryFocalLoss(gamma=2), \n\u001b[1;32m     10\u001b[0m               metrics=['accuracy', jacard_coef])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Attention UNet\n",
        "'''\n",
        "att_unet_model = Attention_UNet(input_shape)\n",
        "\n",
        "att_unet_model.compile(optimizer=Adam(lr = 1e-2), loss=BinaryFocalLoss(gamma=2),\n",
        "              metrics=['accuracy', jacard_coef])\n",
        "\n",
        "\n",
        "print(att_unet_model.summary())\n",
        "start2 = datetime.now()\n",
        "att_unet_history = att_unet_model.fit(X_train, y_train,\n",
        "                    verbose=1,\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=50)\n",
        "stop2 = datetime.now()\n",
        "#Execution time of the model\n",
        "execution_time_Att_Unet = stop2-start2\n",
        "print(\"Attention UNet execution time is: \", execution_time_Att_Unet)\n",
        "\n",
        "att_unet_model.save('brain_Attention_UNet_50epochs_B_focal.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtI31TbX_DEm",
        "outputId": "33416128-3442-41ab-c7e7-bb617e8767ae"
      },
      "execution_count": 38,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Attention_UNet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 128, 128, 64  1792        ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 128, 128, 64  256        ['conv2d_38[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_38[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 128, 128, 64  36928       ['activation_38[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 128, 128, 64  256        ['conv2d_39[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_39[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 64)  0           ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 64, 64, 128)  73856       ['max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 64, 64, 128)  512        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 64, 64, 128)  512        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 128)  0          ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 32, 32, 256)  295168      ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 16, 16, 256)  0          ['activation_43[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 16, 16, 512)  1180160     ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 8, 8, 512)   0           ['activation_45[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 8, 8, 1024)   4719616     ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 8, 8, 1024)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 8, 8, 1024)   9438208     ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 8, 8, 1024)   0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 8, 8, 512)    524800      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 8, 8, 512)    262656      ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 8, 8, 512)   2359808     ['conv2d_50[0][0]']              \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 8, 8, 512)    1049088     ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 8, 8, 512)    0           ['conv2d_transpose[0][0]',       \n",
            "                                                                  'conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 8, 8, 512)    0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 8, 8, 1)      513         ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 8, 8, 1)      0           ['conv2d_51[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_8 (UpSampling2D)  (None, 16, 16, 1)   0           ['activation_50[0][0]']          \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 16, 16, 512)  0           ['up_sampling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 16, 16, 512)  0           ['lambda[0][0]',                 \n",
            "                                                                  'activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 16, 16, 512)  262656      ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_9 (UpSampling2D)  (None, 16, 16, 1024  0          ['activation_47[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 16, 16, 1536  0           ['up_sampling2d_9[0][0]',        \n",
            "                                )                                 'batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 16, 16, 512)  7078400     ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 16, 16, 256)  131328      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 16, 16, 256)  65792       ['activation_53[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 256)  590080     ['conv2d_57[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 16, 16, 256)  262400      ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 256)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'conv2d_56[0][0]']              \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 16, 16, 256)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 16, 16, 1)    257         ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 16, 16, 1)    0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_10 (UpSampling2D  (None, 32, 32, 1)   0           ['activation_55[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 32, 32, 256)  0           ['up_sampling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 32, 32, 256)  0           ['lambda_1[0][0]',               \n",
            "                                                                  'activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 32, 32, 256)  65792       ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_11 (UpSampling2D  (None, 32, 32, 512)  0          ['activation_52[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 32, 32, 768)  0           ['up_sampling2d_11[0][0]',       \n",
            "                                                                  'batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 32, 32, 256)  1769728     ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 32, 32, 128)  32896       ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 32, 32, 128)  512        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 32, 32, 128)  16512       ['activation_58[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 128)  147584     ['conv2d_64[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 32, 32, 128)  65664       ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 128)  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                                                  'conv2d_63[0][0]']              \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 32, 32, 128)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 32, 32, 1)    129         ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 32, 32, 1)    0           ['conv2d_65[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_12 (UpSampling2D  (None, 64, 64, 1)   0           ['activation_60[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 64, 64, 128)  0           ['up_sampling2d_12[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 64, 64, 128)  0           ['lambda_2[0][0]',               \n",
            "                                                                  'activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 64, 64, 128)  16512       ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_13 (UpSampling2D  (None, 64, 64, 256)  0          ['activation_57[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 64, 64, 128)  512        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 64, 64, 384)  0           ['up_sampling2d_13[0][0]',       \n",
            "                                                                  'batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 64, 64, 128)  442496      ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 64, 64, 128)  512        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 64, 64, 128)  512        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 64, 64, 64)   8256        ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 64, 64, 64)  256         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 64, 64, 64)   4160        ['activation_63[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 64, 64, 64)  36928       ['conv2d_71[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 64, 64, 64)   16448       ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 64, 64, 64)   0           ['conv2d_transpose_3[0][0]',     \n",
            "                                                                  'conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 64, 64, 64)   0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 64, 64, 1)    65          ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 64, 64, 1)    0           ['conv2d_72[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_14 (UpSampling2D  (None, 128, 128, 1)  0          ['activation_65[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 128, 128, 64  0           ['up_sampling2d_14[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 128, 128, 64  0           ['lambda_3[0][0]',               \n",
            "                                )                                 'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 128, 128, 64  4160        ['multiply_3[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_15 (UpSampling2D  (None, 128, 128, 12  0          ['activation_62[0][0]']          \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 128, 128, 64  256        ['conv2d_73[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 128, 128, 19  0           ['up_sampling2d_15[0][0]',       \n",
            "                                2)                                'batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 128, 128, 64  110656      ['concatenate_11[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 128, 128, 64  256        ['conv2d_74[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_62[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 128, 128, 64  36928       ['activation_66[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 128, 128, 64  256        ['conv2d_75[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_63[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 128, 128, 1)  65          ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 128, 128, 1)  4          ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 128, 128, 1)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 37,334,665\n",
            "Trainable params: 37,319,047\n",
            "Non-trainable params: 15,618\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "442/442 [==============================] - 122s 205ms/step - loss: 0.1372 - accuracy: 0.8237 - jacard_coef: 0.0104 - val_loss: 0.1108 - val_accuracy: 0.9893 - val_jacard_coef: 0.0084\n",
            "Epoch 2/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0727 - accuracy: 0.9851 - jacard_coef: 0.0104 - val_loss: 0.0523 - val_accuracy: 0.9895 - val_jacard_coef: 0.0090\n",
            "Epoch 3/50\n",
            "442/442 [==============================] - 92s 208ms/step - loss: 0.0461 - accuracy: 0.9872 - jacard_coef: 0.0112 - val_loss: 0.0352 - val_accuracy: 0.9895 - val_jacard_coef: 0.0098\n",
            "Epoch 4/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0309 - accuracy: 0.9878 - jacard_coef: 0.0147 - val_loss: 0.0271 - val_accuracy: 0.9887 - val_jacard_coef: 0.0131\n",
            "Epoch 5/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0224 - accuracy: 0.9887 - jacard_coef: 0.0172 - val_loss: 0.0206 - val_accuracy: 0.9874 - val_jacard_coef: 0.0160\n",
            "Epoch 6/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0178 - accuracy: 0.9892 - jacard_coef: 0.0192 - val_loss: 0.0159 - val_accuracy: 0.9903 - val_jacard_coef: 0.0165\n",
            "Epoch 7/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0151 - accuracy: 0.9893 - jacard_coef: 0.0210 - val_loss: 0.0136 - val_accuracy: 0.9906 - val_jacard_coef: 0.0185\n",
            "Epoch 8/50\n",
            "442/442 [==============================] - 91s 207ms/step - loss: 0.0134 - accuracy: 0.9894 - jacard_coef: 0.0228 - val_loss: 0.0123 - val_accuracy: 0.9898 - val_jacard_coef: 0.0202\n",
            "Epoch 9/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0122 - accuracy: 0.9895 - jacard_coef: 0.0247 - val_loss: 0.0111 - val_accuracy: 0.9906 - val_jacard_coef: 0.0205\n",
            "Epoch 10/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0111 - accuracy: 0.9897 - jacard_coef: 0.0271 - val_loss: 0.0101 - val_accuracy: 0.9908 - val_jacard_coef: 0.0248\n",
            "Epoch 11/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0104 - accuracy: 0.9898 - jacard_coef: 0.0293 - val_loss: 0.0102 - val_accuracy: 0.9899 - val_jacard_coef: 0.0258\n",
            "Epoch 12/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0099 - accuracy: 0.9899 - jacard_coef: 0.0313 - val_loss: 0.0119 - val_accuracy: 0.9863 - val_jacard_coef: 0.0287\n",
            "Epoch 13/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0094 - accuracy: 0.9900 - jacard_coef: 0.0335 - val_loss: 0.0087 - val_accuracy: 0.9914 - val_jacard_coef: 0.0281\n",
            "Epoch 14/50\n",
            "442/442 [==============================] - 89s 201ms/step - loss: 0.0091 - accuracy: 0.9900 - jacard_coef: 0.0355 - val_loss: 0.0082 - val_accuracy: 0.9914 - val_jacard_coef: 0.0313\n",
            "Epoch 15/50\n",
            "442/442 [==============================] - 89s 201ms/step - loss: 0.0086 - accuracy: 0.9901 - jacard_coef: 0.0381 - val_loss: 0.0092 - val_accuracy: 0.9899 - val_jacard_coef: 0.0364\n",
            "Epoch 16/50\n",
            "442/442 [==============================] - 89s 201ms/step - loss: 0.0083 - accuracy: 0.9903 - jacard_coef: 0.0404 - val_loss: 0.0086 - val_accuracy: 0.9901 - val_jacard_coef: 0.0384\n",
            "Epoch 17/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0080 - accuracy: 0.9904 - jacard_coef: 0.0429 - val_loss: 0.0079 - val_accuracy: 0.9905 - val_jacard_coef: 0.0405\n",
            "Epoch 18/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0076 - accuracy: 0.9905 - jacard_coef: 0.0455 - val_loss: 0.0079 - val_accuracy: 0.9906 - val_jacard_coef: 0.0407\n",
            "Epoch 19/50\n",
            "442/442 [==============================] - 89s 201ms/step - loss: 0.0074 - accuracy: 0.9906 - jacard_coef: 0.0479 - val_loss: 0.0071 - val_accuracy: 0.9913 - val_jacard_coef: 0.0427\n",
            "Epoch 20/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0071 - accuracy: 0.9907 - jacard_coef: 0.0503 - val_loss: 0.0070 - val_accuracy: 0.9911 - val_jacard_coef: 0.0449\n",
            "Epoch 21/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0068 - accuracy: 0.9908 - jacard_coef: 0.0529 - val_loss: 0.0076 - val_accuracy: 0.9895 - val_jacard_coef: 0.0479\n",
            "Epoch 22/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0066 - accuracy: 0.9909 - jacard_coef: 0.0555 - val_loss: 0.0072 - val_accuracy: 0.9906 - val_jacard_coef: 0.0469\n",
            "Epoch 23/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0066 - accuracy: 0.9909 - jacard_coef: 0.0569 - val_loss: 0.0065 - val_accuracy: 0.9918 - val_jacard_coef: 0.0478\n",
            "Epoch 24/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0063 - accuracy: 0.9909 - jacard_coef: 0.0594 - val_loss: 0.0088 - val_accuracy: 0.9870 - val_jacard_coef: 0.0514\n",
            "Epoch 25/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0061 - accuracy: 0.9910 - jacard_coef: 0.0621 - val_loss: 0.0075 - val_accuracy: 0.9895 - val_jacard_coef: 0.0498\n",
            "Epoch 26/50\n",
            "442/442 [==============================] - 91s 207ms/step - loss: 0.0059 - accuracy: 0.9911 - jacard_coef: 0.0641 - val_loss: 0.0068 - val_accuracy: 0.9914 - val_jacard_coef: 0.0517\n",
            "Epoch 27/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0057 - accuracy: 0.9913 - jacard_coef: 0.0669 - val_loss: 0.0092 - val_accuracy: 0.9854 - val_jacard_coef: 0.0516\n",
            "Epoch 28/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0056 - accuracy: 0.9913 - jacard_coef: 0.0687 - val_loss: 0.0078 - val_accuracy: 0.9885 - val_jacard_coef: 0.0567\n",
            "Epoch 29/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0054 - accuracy: 0.9914 - jacard_coef: 0.0712 - val_loss: 0.0077 - val_accuracy: 0.9893 - val_jacard_coef: 0.0639\n",
            "Epoch 30/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0052 - accuracy: 0.9916 - jacard_coef: 0.0734 - val_loss: 0.0093 - val_accuracy: 0.9868 - val_jacard_coef: 0.0571\n",
            "Epoch 31/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0050 - accuracy: 0.9917 - jacard_coef: 0.0759 - val_loss: 0.0078 - val_accuracy: 0.9895 - val_jacard_coef: 0.0642\n",
            "Epoch 32/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0049 - accuracy: 0.9917 - jacard_coef: 0.0778 - val_loss: 0.0079 - val_accuracy: 0.9890 - val_jacard_coef: 0.0678\n",
            "Epoch 33/50\n",
            "442/442 [==============================] - 89s 201ms/step - loss: 0.0047 - accuracy: 0.9920 - jacard_coef: 0.0807 - val_loss: 0.0083 - val_accuracy: 0.9880 - val_jacard_coef: 0.0689\n",
            "Epoch 34/50\n",
            "442/442 [==============================] - 89s 201ms/step - loss: 0.0045 - accuracy: 0.9920 - jacard_coef: 0.0832 - val_loss: 0.0106 - val_accuracy: 0.9839 - val_jacard_coef: 0.0581\n",
            "Epoch 35/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0044 - accuracy: 0.9922 - jacard_coef: 0.0858 - val_loss: 0.0079 - val_accuracy: 0.9897 - val_jacard_coef: 0.0619\n",
            "Epoch 36/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0044 - accuracy: 0.9922 - jacard_coef: 0.0871 - val_loss: 0.0074 - val_accuracy: 0.9898 - val_jacard_coef: 0.0683\n",
            "Epoch 37/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0041 - accuracy: 0.9924 - jacard_coef: 0.0913 - val_loss: 0.0075 - val_accuracy: 0.9895 - val_jacard_coef: 0.0701\n",
            "Epoch 38/50\n",
            "442/442 [==============================] - 89s 201ms/step - loss: 0.0039 - accuracy: 0.9925 - jacard_coef: 0.0948 - val_loss: 0.0071 - val_accuracy: 0.9903 - val_jacard_coef: 0.0728\n",
            "Epoch 39/50\n",
            "442/442 [==============================] - 91s 207ms/step - loss: 0.0039 - accuracy: 0.9926 - jacard_coef: 0.0967 - val_loss: 0.0083 - val_accuracy: 0.9884 - val_jacard_coef: 0.0710\n",
            "Epoch 40/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0038 - accuracy: 0.9927 - jacard_coef: 0.0991 - val_loss: 0.0067 - val_accuracy: 0.9924 - val_jacard_coef: 0.0707\n",
            "Epoch 41/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0036 - accuracy: 0.9929 - jacard_coef: 0.1029 - val_loss: 0.0070 - val_accuracy: 0.9912 - val_jacard_coef: 0.0673\n",
            "Epoch 42/50\n",
            "442/442 [==============================] - 91s 207ms/step - loss: 0.0036 - accuracy: 0.9928 - jacard_coef: 0.1047 - val_loss: 0.0072 - val_accuracy: 0.9909 - val_jacard_coef: 0.0785\n",
            "Epoch 43/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0036 - accuracy: 0.9928 - jacard_coef: 0.1060 - val_loss: 0.0070 - val_accuracy: 0.9916 - val_jacard_coef: 0.0778\n",
            "Epoch 44/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0033 - accuracy: 0.9931 - jacard_coef: 0.1104 - val_loss: 0.0068 - val_accuracy: 0.9920 - val_jacard_coef: 0.0822\n",
            "Epoch 45/50\n",
            "442/442 [==============================] - 91s 207ms/step - loss: 0.0032 - accuracy: 0.9932 - jacard_coef: 0.1138 - val_loss: 0.0080 - val_accuracy: 0.9914 - val_jacard_coef: 0.0881\n",
            "Epoch 46/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0033 - accuracy: 0.9931 - jacard_coef: 0.1141 - val_loss: 0.0068 - val_accuracy: 0.9922 - val_jacard_coef: 0.0779\n",
            "Epoch 47/50\n",
            "442/442 [==============================] - 91s 206ms/step - loss: 0.0031 - accuracy: 0.9934 - jacard_coef: 0.1192 - val_loss: 0.0079 - val_accuracy: 0.9921 - val_jacard_coef: 0.0828\n",
            "Epoch 48/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0029 - accuracy: 0.9935 - jacard_coef: 0.1228 - val_loss: 0.0076 - val_accuracy: 0.9920 - val_jacard_coef: 0.0764\n",
            "Epoch 49/50\n",
            "442/442 [==============================] - 89s 201ms/step - loss: 0.0029 - accuracy: 0.9936 - jacard_coef: 0.1252 - val_loss: 0.0073 - val_accuracy: 0.9920 - val_jacard_coef: 0.0851\n",
            "Epoch 50/50\n",
            "442/442 [==============================] - 89s 202ms/step - loss: 0.0028 - accuracy: 0.9936 - jacard_coef: 0.1279 - val_loss: 0.0083 - val_accuracy: 0.9925 - val_jacard_coef: 0.0773\n",
            "Attention UNet execution time is:  1:16:37.459502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#___________________________________________\n",
        "'''\n",
        "Attention Residual Unet\n",
        "'''\n",
        "att_res_unet_model = Attention_ResUNet(input_shape)\n",
        "\n",
        "att_res_unet_model.compile(optimizer=Adam(lr = 1e-2), loss=BinaryFocalLoss(gamma=2),\n",
        "              metrics=['accuracy', jacard_coef])\n",
        "\n",
        "\n",
        "# att_res_unet_model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy',\n",
        "#               metrics=['accuracy', jacard_coef])\n",
        "\n",
        "print(att_res_unet_model.summary())\n",
        "\n",
        "\n",
        "start3 = datetime.now()\n",
        "att_res_unet_history = att_res_unet_model.fit(X_train, y_train,\n",
        "                    verbose=1,\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=50)\n",
        "stop3 = datetime.now()\n",
        "\n",
        "#Execution time of the model\n",
        "execution_time_AttResUnet = stop3-start3\n",
        "print(\"Attention ResUnet execution time is: \", execution_time_AttResUnet)\n",
        "\n",
        "att_res_unet_model.save('brain_AttResUnet_50epochs_B_focal.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SlevGXe_DC2",
        "outputId": "048dcdca-5a41-4251-8842-9007b10e583a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"AttentionResUNet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 128, 128, 64  1792        ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 128, 128, 64  256        ['conv2d_19[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_19[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 128, 128, 64  256         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 128, 128, 64  36928       ['activation_19[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 128, 128, 64  256        ['conv2d_21[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 128, 128, 64  256        ['conv2d_20[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 128, 128, 64  0           ['batch_normalization_21[0][0]', \n",
            "                                )                                 'batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 128, 128, 64  0           ['add[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 64)  0           ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 64, 64, 128)  73856       ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 64, 64, 128)  512        ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 64, 64, 128)  8320        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 64, 64, 128)  512        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 64, 64, 128)  512        ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 64, 64, 128)  0           ['batch_normalization_24[0][0]', \n",
            "                                                                  'batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 64, 64, 128)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 128)  0          ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 32, 32, 256)  295168      ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 32, 32, 256)  33024       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 256)  0           ['batch_normalization_27[0][0]', \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 32, 32, 256)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 256)  0          ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 512)  1180160     ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 512)  131584      ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 512)  0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 16, 16, 512)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 512)   0           ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 8, 8, 1024)   4719616     ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 8, 8, 1024)   0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 8, 8, 1024)   525312      ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 8, 8, 1024)   9438208     ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 8, 8, 1024)   0           ['batch_normalization_33[0][0]', \n",
            "                                                                  'batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 8, 8, 1024)   0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 8, 8, 512)    524800      ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 8, 8, 512)    262656      ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 8, 8, 512)   2359808     ['conv2d_36[0][0]']              \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 8, 8, 512)    1049088     ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 8, 8, 512)    0           ['conv2d_transpose[0][0]',       \n",
            "                                                                  'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 8, 8, 512)    0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 8, 8, 1)      513         ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 8, 8, 1)      0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 1)   0           ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 16, 16, 512)  0           ['up_sampling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 16, 16, 512)  0           ['lambda[0][0]',                 \n",
            "                                                                  'activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 16, 16, 512)  262656      ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 1024  0          ['activation_28[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 16, 16, 1536  0           ['up_sampling2d_5[0][0]',        \n",
            "                                )                                 'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 16, 16, 512)  7078400     ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 16, 16, 512)  786944      ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 16, 16, 512)  0           ['batch_normalization_38[0][0]', \n",
            "                                                                  'batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 16, 16, 512)  0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 16, 16, 256)  131328      ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 16, 16, 256)  65792       ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 256)  590080     ['conv2d_44[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 16, 16, 256)  262400      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 256)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 16, 16, 256)  0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 16, 16, 1)    257         ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 16, 16, 1)    0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 1)   0           ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 32, 32, 256)  0           ['up_sampling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 32, 32, 256)  0           ['lambda_1[0][0]',               \n",
            "                                                                  'activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 32, 32, 256)  65792       ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 32, 32, 512)  0          ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 32, 32, 768)  0           ['up_sampling2d_7[0][0]',        \n",
            "                                                                  'batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 32, 32, 256)  1769728     ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 32, 32, 256)  196864      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 32, 32, 256)  0           ['batch_normalization_43[0][0]', \n",
            "                                                                  'batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 32, 32, 256)  0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 32, 32, 128)  32896       ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 32, 32, 128)  512        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 32, 32, 128)  16512       ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 128)  147584     ['conv2d_52[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 32, 32, 128)  65664       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 32, 128)  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                                                  'conv2d_51[0][0]']              \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 32, 32, 128)  0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 32, 32, 1)    129         ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 32, 32, 1)    0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_8 (UpSampling2D)  (None, 64, 64, 1)   0           ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 64, 64, 128)  0           ['up_sampling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 64, 64, 128)  0           ['lambda_2[0][0]',               \n",
            "                                                                  'activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 64, 64, 128)  16512       ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_9 (UpSampling2D)  (None, 64, 64, 256)  0          ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 64, 64, 128)  512        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 64, 64, 384)  0           ['up_sampling2d_9[0][0]',        \n",
            "                                                                  'batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 64, 64, 128)  442496      ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 64, 64, 128)  512        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 64, 64, 128)  49280       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 64, 64, 128)  512        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 64, 64, 128)  512        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 64, 64, 128)  0           ['batch_normalization_48[0][0]', \n",
            "                                                                  'batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 64, 64, 128)  0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 64, 64, 64)   8256        ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 64, 64, 64)  256         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 64, 64, 64)   4160        ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 64, 64, 64)  36928       ['conv2d_60[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 64, 64, 64)   16448       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 64, 64, 64)   0           ['conv2d_transpose_3[0][0]',     \n",
            "                                                                  'conv2d_59[0][0]']              \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 64, 64, 64)   0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 64, 64, 1)    65          ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 64, 64, 1)    0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_10 (UpSampling2D  (None, 128, 128, 1)  0          ['activation_46[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 128, 128, 64  0           ['up_sampling2d_10[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 128, 128, 64  0           ['lambda_3[0][0]',               \n",
            "                                )                                 'activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 128, 128, 64  4160        ['multiply_3[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_11 (UpSampling2D  (None, 128, 128, 12  0          ['activation_43[0][0]']          \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 128, 128, 64  256        ['conv2d_62[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 128, 128, 19  0           ['up_sampling2d_11[0][0]',       \n",
            "                                2)                                'batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 128, 128, 64  110656      ['concatenate_7[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 128, 128, 64  256        ['conv2d_63[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_51[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 128, 128, 64  12352       ['concatenate_7[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 128, 128, 64  36928       ['activation_47[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 128, 128, 64  256        ['conv2d_65[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 128, 128, 64  256        ['conv2d_64[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 128, 128, 64  0           ['batch_normalization_53[0][0]', \n",
            "                                )                                 'batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 128, 128, 64  0           ['add_12[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 128, 128, 1)  65          ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 128, 128, 1)  4          ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 128, 128, 1)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 39,090,377\n",
            "Trainable params: 39,068,871\n",
            "Non-trainable params: 21,506\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "442/442 [==============================] - 177s 227ms/step - loss: 0.1330 - accuracy: 0.8811 - jacard_coef: 0.0107 - val_loss: 0.0904 - val_accuracy: 0.9895 - val_jacard_coef: 0.0087\n",
            "Epoch 2/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0707 - accuracy: 0.9864 - jacard_coef: 0.0109 - val_loss: 0.0542 - val_accuracy: 0.9895 - val_jacard_coef: 0.0087\n",
            "Epoch 3/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0430 - accuracy: 0.9875 - jacard_coef: 0.0137 - val_loss: 0.0385 - val_accuracy: 0.9763 - val_jacard_coef: 0.0163\n",
            "Epoch 4/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0280 - accuracy: 0.9893 - jacard_coef: 0.0182 - val_loss: 0.0229 - val_accuracy: 0.9896 - val_jacard_coef: 0.0187\n",
            "Epoch 5/50\n",
            "442/442 [==============================] - 101s 227ms/step - loss: 0.0203 - accuracy: 0.9900 - jacard_coef: 0.0212 - val_loss: 0.0164 - val_accuracy: 0.9912 - val_jacard_coef: 0.0202\n",
            "Epoch 6/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0157 - accuracy: 0.9904 - jacard_coef: 0.0240 - val_loss: 0.0133 - val_accuracy: 0.9915 - val_jacard_coef: 0.0214\n",
            "Epoch 7/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0128 - accuracy: 0.9907 - jacard_coef: 0.0267 - val_loss: 0.0124 - val_accuracy: 0.9901 - val_jacard_coef: 0.0238\n",
            "Epoch 8/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0112 - accuracy: 0.9905 - jacard_coef: 0.0283 - val_loss: 0.0116 - val_accuracy: 0.9884 - val_jacard_coef: 0.0268\n",
            "Epoch 9/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0094 - accuracy: 0.9910 - jacard_coef: 0.0321 - val_loss: 0.0085 - val_accuracy: 0.9919 - val_jacard_coef: 0.0284\n",
            "Epoch 10/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0083 - accuracy: 0.9913 - jacard_coef: 0.0353 - val_loss: 0.0098 - val_accuracy: 0.9913 - val_jacard_coef: 0.0239\n",
            "Epoch 11/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0082 - accuracy: 0.9909 - jacard_coef: 0.0362 - val_loss: 0.0138 - val_accuracy: 0.9899 - val_jacard_coef: 0.0154\n",
            "Epoch 12/50\n",
            "442/442 [==============================] - 99s 223ms/step - loss: 0.0085 - accuracy: 0.9903 - jacard_coef: 0.0358 - val_loss: 0.0076 - val_accuracy: 0.9914 - val_jacard_coef: 0.0326\n",
            "Epoch 13/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0075 - accuracy: 0.9906 - jacard_coef: 0.0402 - val_loss: 0.0068 - val_accuracy: 0.9917 - val_jacard_coef: 0.0372\n",
            "Epoch 14/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0072 - accuracy: 0.9909 - jacard_coef: 0.0430 - val_loss: 0.0069 - val_accuracy: 0.9919 - val_jacard_coef: 0.0376\n",
            "Epoch 15/50\n",
            "442/442 [==============================] - 101s 227ms/step - loss: 0.0064 - accuracy: 0.9914 - jacard_coef: 0.0476 - val_loss: 0.0065 - val_accuracy: 0.9921 - val_jacard_coef: 0.0417\n",
            "Epoch 16/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0057 - accuracy: 0.9918 - jacard_coef: 0.0523 - val_loss: 0.0063 - val_accuracy: 0.9918 - val_jacard_coef: 0.0463\n",
            "Epoch 17/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0053 - accuracy: 0.9920 - jacard_coef: 0.0564 - val_loss: 0.0065 - val_accuracy: 0.9915 - val_jacard_coef: 0.0509\n",
            "Epoch 18/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0049 - accuracy: 0.9922 - jacard_coef: 0.0607 - val_loss: 0.0066 - val_accuracy: 0.9911 - val_jacard_coef: 0.0536\n",
            "Epoch 19/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0047 - accuracy: 0.9922 - jacard_coef: 0.0642 - val_loss: 0.0069 - val_accuracy: 0.9907 - val_jacard_coef: 0.0517\n",
            "Epoch 20/50\n",
            "442/442 [==============================] - 101s 227ms/step - loss: 0.0044 - accuracy: 0.9924 - jacard_coef: 0.0683 - val_loss: 0.0062 - val_accuracy: 0.9916 - val_jacard_coef: 0.0583\n",
            "Epoch 21/50\n",
            "442/442 [==============================] - 99s 223ms/step - loss: 0.0040 - accuracy: 0.9925 - jacard_coef: 0.0737 - val_loss: 0.0070 - val_accuracy: 0.9910 - val_jacard_coef: 0.0571\n",
            "Epoch 22/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0037 - accuracy: 0.9928 - jacard_coef: 0.0786 - val_loss: 0.0074 - val_accuracy: 0.9904 - val_jacard_coef: 0.0648\n",
            "Epoch 23/50\n",
            "442/442 [==============================] - 99s 223ms/step - loss: 0.0036 - accuracy: 0.9929 - jacard_coef: 0.0828 - val_loss: 0.0080 - val_accuracy: 0.9896 - val_jacard_coef: 0.0712\n",
            "Epoch 24/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0035 - accuracy: 0.9929 - jacard_coef: 0.0858 - val_loss: 0.0071 - val_accuracy: 0.9905 - val_jacard_coef: 0.0730\n",
            "Epoch 25/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0033 - accuracy: 0.9931 - jacard_coef: 0.0911 - val_loss: 0.0071 - val_accuracy: 0.9912 - val_jacard_coef: 0.0733\n",
            "Epoch 26/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0031 - accuracy: 0.9933 - jacard_coef: 0.0955 - val_loss: 0.0071 - val_accuracy: 0.9910 - val_jacard_coef: 0.0813\n",
            "Epoch 27/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0030 - accuracy: 0.9934 - jacard_coef: 0.0997 - val_loss: 0.0072 - val_accuracy: 0.9919 - val_jacard_coef: 0.0745\n",
            "Epoch 28/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0029 - accuracy: 0.9935 - jacard_coef: 0.1029 - val_loss: 0.0068 - val_accuracy: 0.9918 - val_jacard_coef: 0.0854\n",
            "Epoch 29/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0027 - accuracy: 0.9936 - jacard_coef: 0.1084 - val_loss: 0.0070 - val_accuracy: 0.9920 - val_jacard_coef: 0.0878\n",
            "Epoch 30/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0025 - accuracy: 0.9938 - jacard_coef: 0.1134 - val_loss: 0.0067 - val_accuracy: 0.9925 - val_jacard_coef: 0.0819\n",
            "Epoch 31/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0024 - accuracy: 0.9939 - jacard_coef: 0.1175 - val_loss: 0.0068 - val_accuracy: 0.9928 - val_jacard_coef: 0.0774\n",
            "Epoch 32/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0023 - accuracy: 0.9941 - jacard_coef: 0.1220 - val_loss: 0.0068 - val_accuracy: 0.9923 - val_jacard_coef: 0.0815\n",
            "Epoch 33/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0022 - accuracy: 0.9942 - jacard_coef: 0.1266 - val_loss: 0.0075 - val_accuracy: 0.9926 - val_jacard_coef: 0.0792\n",
            "Epoch 34/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0021 - accuracy: 0.9943 - jacard_coef: 0.1315 - val_loss: 0.0078 - val_accuracy: 0.9925 - val_jacard_coef: 0.0836\n",
            "Epoch 35/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0021 - accuracy: 0.9944 - jacard_coef: 0.1347 - val_loss: 0.0074 - val_accuracy: 0.9925 - val_jacard_coef: 0.0865\n",
            "Epoch 36/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0020 - accuracy: 0.9945 - jacard_coef: 0.1386 - val_loss: 0.0077 - val_accuracy: 0.9928 - val_jacard_coef: 0.0862\n",
            "Epoch 37/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0019 - accuracy: 0.9946 - jacard_coef: 0.1439 - val_loss: 0.0077 - val_accuracy: 0.9928 - val_jacard_coef: 0.0913\n",
            "Epoch 38/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0019 - accuracy: 0.9946 - jacard_coef: 0.1453 - val_loss: 0.0081 - val_accuracy: 0.9927 - val_jacard_coef: 0.0972\n",
            "Epoch 39/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0020 - accuracy: 0.9945 - jacard_coef: 0.1462 - val_loss: 0.0084 - val_accuracy: 0.9925 - val_jacard_coef: 0.0935\n",
            "Epoch 40/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0018 - accuracy: 0.9947 - jacard_coef: 0.1523 - val_loss: 0.0083 - val_accuracy: 0.9929 - val_jacard_coef: 0.1094\n",
            "Epoch 41/50\n",
            "442/442 [==============================] - 99s 223ms/step - loss: 0.0016 - accuracy: 0.9949 - jacard_coef: 0.1592 - val_loss: 0.0086 - val_accuracy: 0.9925 - val_jacard_coef: 0.1078\n",
            "Epoch 42/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0015 - accuracy: 0.9949 - jacard_coef: 0.1633 - val_loss: 0.0080 - val_accuracy: 0.9923 - val_jacard_coef: 0.1124\n",
            "Epoch 43/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0015 - accuracy: 0.9949 - jacard_coef: 0.1651 - val_loss: 0.0086 - val_accuracy: 0.9929 - val_jacard_coef: 0.1216\n",
            "Epoch 44/50\n",
            "442/442 [==============================] - 99s 224ms/step - loss: 0.0014 - accuracy: 0.9951 - jacard_coef: 0.1717 - val_loss: 0.0088 - val_accuracy: 0.9926 - val_jacard_coef: 0.1145\n",
            "Epoch 45/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0013 - accuracy: 0.9951 - jacard_coef: 0.1763 - val_loss: 0.0091 - val_accuracy: 0.9926 - val_jacard_coef: 0.1312\n",
            "Epoch 46/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0014 - accuracy: 0.9951 - jacard_coef: 0.1786 - val_loss: 0.0088 - val_accuracy: 0.9920 - val_jacard_coef: 0.1232\n",
            "Epoch 47/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0016 - accuracy: 0.9950 - jacard_coef: 0.1762 - val_loss: 0.0093 - val_accuracy: 0.9919 - val_jacard_coef: 0.1316\n",
            "Epoch 48/50\n",
            "442/442 [==============================] - 101s 228ms/step - loss: 0.0013 - accuracy: 0.9951 - jacard_coef: 0.1852 - val_loss: 0.0100 - val_accuracy: 0.9918 - val_jacard_coef: 0.1318\n",
            "Epoch 49/50\n",
            "442/442 [==============================] - 99s 223ms/step - loss: 0.0011 - accuracy: 0.9953 - jacard_coef: 0.1939 - val_loss: 0.0102 - val_accuracy: 0.9920 - val_jacard_coef: 0.1352\n",
            "Epoch 50/50\n",
            "442/442 [==============================] - 100s 227ms/step - loss: 0.0010 - accuracy: 0.9954 - jacard_coef: 0.1998 - val_loss: 0.0105 - val_accuracy: 0.9923 - val_jacard_coef: 0.1295\n",
            "Attention ResUnet execution time is:  1:24:56.897110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the history.history dict to a pandas DataFrame and save as csv for\n",
        "# future plotting\n",
        "import pandas as pd\n",
        "unet_history_df = pd.DataFrame(unet_history.history)\n",
        "att_unet_history_df = pd.DataFrame(att_unet_history.history)\n",
        "att_res_unet_history_df = pd.DataFrame(att_res_unet_history.history)\n",
        "\n",
        "with open('unet_history_df.csv', mode='w') as f:\n",
        "    unet_history_df.to_csv(f)\n",
        "\n",
        "with open('att_unet_history_df.csv', mode='w') as f:\n",
        "    att_unet_history_df.to_csv(f)\n",
        "\n",
        "with open('custom_code_att_res_unet_history_df.csv', mode='w') as f:\n",
        "    att_res_unet_history_df.to_csv(f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "3zvBss6a_DA3",
        "outputId": "4b8900a2-e9a6-4fad-fd6d-c80fd2823b0f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-8bc698d0d6b5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# future plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0munet_history_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0matt_unet_history_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_unet_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0matt_res_unet_history_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_res_unet_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'unet_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check history plots, one model at a time\n",
        "history = unet_history\n",
        "history = att_unet_history\n",
        "history = att_res_unet_history\n",
        "\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "HZVEnPmw_C91",
        "outputId": "60285642-6b9a-4c97-aeb8-72aedca9f134"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-0fe889b912d2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Check history plots, one model at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt_unet_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt_res_unet_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'unet_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['jacard_coef']\n",
        "#acc = history.history['accuracy']\n",
        "val_acc = history.history['val_jacard_coef']\n",
        "#val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training Jacard')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Jacard')\n",
        "plt.title('Training and validation Jacard')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Jacard')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P8wohTEm_C5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_model\n",
        "model = att_unet_model\n",
        "model = att_res_unet_model\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/brain_UNet_50epochs_B_focal.hdf5\"\n",
        "model_path = \"/content/drive/MyDrive/brain_Attention_UNet_50epochs_B_focal.hdf5\"\n",
        "model_path = \"/content/drive/MyDrive/brain_AttResUnet_50epochs_B_focal.hdf5\"\n",
        "#Load one model at a time for testing.\n",
        "model = tf.keras.models.load_model(model_path, compile=False)"
      ],
      "metadata": {
        "id": "dsukUOMl_2wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "test_img_number = random.randint(0, X_test.shape[0]-1)\n",
        "test_img = X_test[test_img_number]\n",
        "ground_truth=y_test[test_img_number]\n",
        "\n",
        "test_img_input=np.expand_dims(test_img, 0)\n",
        "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img, cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wl2kIITj_2uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IoU for a single image\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "n_classes = 2\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)\n",
        "IOU_keras.update_state(ground_truth[:,:,0], prediction)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ],
      "metadata": {
        "id": "bSisYhWW_2pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate IoU for all test images and average\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "IoU_values = []\n",
        "for img in range(0, X_test.shape[0]):\n",
        "    temp_img = X_test[img]\n",
        "    ground_truth=y_test[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
        "\n",
        "    IoU = MeanIoU(num_classes=n_classes)\n",
        "    IoU.update_state(ground_truth[:,:,0], prediction)\n",
        "    IoU = IoU.result().numpy()\n",
        "    IoU_values.append(IoU)\n",
        "\n",
        "    print(IoU)"
      ],
      "metadata": {
        "id": "Eip75AGa_2lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(IoU_values, columns=[\"IoU\"])\n",
        "df = df[df.IoU != 1.0]\n",
        "mean_IoU = df.mean().values\n",
        "print(\"Mean IoU is: \", mean_IoU)"
      ],
      "metadata": {
        "id": "capd8Jap_C2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pmTrpb4_Czz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}